{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "896c2bf8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24936/2900427307.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "import glob\n",
    "import tqdm\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, Sequential\n",
    "from sklearn import preprocessing\n",
    "import category_encoders as ce\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import scipy.sparse as sparse\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict, Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, pickle\n",
    "from collections import defaultdict, Counter\n",
    "import tqdm\n",
    "# estimate runningtime : EGES----16 hours; FM----6 hours; whole program: 24 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a280c67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (25,26) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# read the files\n",
    "customer_df = pd.read_csv('./data/customers.csv') \n",
    "sub_df = pd.read_csv('./data/sample_submission.csv') \n",
    "train_df = pd.read_csv('./data/transactions_train.csv', dtype={\"article_id\": str}) \n",
    "article_df = pd.read_csv('./data/articles.csv', dtype={\"article_id\": str}) \n",
    "train_df['t_dat'] = pd.to_datetime(train_df['t_dat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49aa6f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>product_code</th>\n",
       "      <th>prod_name</th>\n",
       "      <th>product_type_no</th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>product_group_name</th>\n",
       "      <th>graphical_appearance_no</th>\n",
       "      <th>graphical_appearance_name</th>\n",
       "      <th>colour_group_code</th>\n",
       "      <th>colour_group_name</th>\n",
       "      <th>...</th>\n",
       "      <th>index_name</th>\n",
       "      <th>index_group_no</th>\n",
       "      <th>index_group_name</th>\n",
       "      <th>section_no</th>\n",
       "      <th>section_name</th>\n",
       "      <th>garment_group_no</th>\n",
       "      <th>garment_group_name</th>\n",
       "      <th>detail_desc</th>\n",
       "      <th>Unnamed: 25</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108775015</td>\n",
       "      <td>108775</td>\n",
       "      <td>Strap top</td>\n",
       "      <td>253</td>\n",
       "      <td>Vest top</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>Solid</td>\n",
       "      <td>9</td>\n",
       "      <td>Black</td>\n",
       "      <td>...</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>1</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>16</td>\n",
       "      <td>Womens Everyday Basics</td>\n",
       "      <td>1002</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>Jersey top with narrow shoulder straps.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108775044</td>\n",
       "      <td>108775</td>\n",
       "      <td>Strap top</td>\n",
       "      <td>253</td>\n",
       "      <td>Vest top</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>Solid</td>\n",
       "      <td>10</td>\n",
       "      <td>White</td>\n",
       "      <td>...</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>1</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>16</td>\n",
       "      <td>Womens Everyday Basics</td>\n",
       "      <td>1002</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>Jersey top with narrow shoulder straps.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108775051</td>\n",
       "      <td>108775</td>\n",
       "      <td>Strap top (1)</td>\n",
       "      <td>253</td>\n",
       "      <td>Vest top</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010017</td>\n",
       "      <td>Stripe</td>\n",
       "      <td>11</td>\n",
       "      <td>Off White</td>\n",
       "      <td>...</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>1</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>16</td>\n",
       "      <td>Womens Everyday Basics</td>\n",
       "      <td>1002</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>Jersey top with narrow shoulder straps.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110065001</td>\n",
       "      <td>110065</td>\n",
       "      <td>OP T-shirt (Idro)</td>\n",
       "      <td>306</td>\n",
       "      <td>Bra</td>\n",
       "      <td>Underwear</td>\n",
       "      <td>1010016</td>\n",
       "      <td>Solid</td>\n",
       "      <td>9</td>\n",
       "      <td>Black</td>\n",
       "      <td>...</td>\n",
       "      <td>Lingeries/Tights</td>\n",
       "      <td>1</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>61</td>\n",
       "      <td>Womens Lingerie</td>\n",
       "      <td>1017</td>\n",
       "      <td>Under-, Nightwear</td>\n",
       "      <td>Microfibre T-shirt bra with underwired, moulde...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110065002</td>\n",
       "      <td>110065</td>\n",
       "      <td>OP T-shirt (Idro)</td>\n",
       "      <td>306</td>\n",
       "      <td>Bra</td>\n",
       "      <td>Underwear</td>\n",
       "      <td>1010016</td>\n",
       "      <td>Solid</td>\n",
       "      <td>10</td>\n",
       "      <td>White</td>\n",
       "      <td>...</td>\n",
       "      <td>Lingeries/Tights</td>\n",
       "      <td>1</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>61</td>\n",
       "      <td>Womens Lingerie</td>\n",
       "      <td>1017</td>\n",
       "      <td>Under-, Nightwear</td>\n",
       "      <td>Microfibre T-shirt bra with underwired, moulde...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id  product_code          prod_name  product_type_no  \\\n",
       "0  108775015        108775          Strap top              253   \n",
       "1  108775044        108775          Strap top              253   \n",
       "2  108775051        108775      Strap top (1)              253   \n",
       "3  110065001        110065  OP T-shirt (Idro)              306   \n",
       "4  110065002        110065  OP T-shirt (Idro)              306   \n",
       "\n",
       "  product_type_name  product_group_name  graphical_appearance_no  \\\n",
       "0          Vest top  Garment Upper body                  1010016   \n",
       "1          Vest top  Garment Upper body                  1010016   \n",
       "2          Vest top  Garment Upper body                  1010017   \n",
       "3               Bra           Underwear                  1010016   \n",
       "4               Bra           Underwear                  1010016   \n",
       "\n",
       "  graphical_appearance_name  colour_group_code colour_group_name  ...  \\\n",
       "0                     Solid                  9             Black  ...   \n",
       "1                     Solid                 10             White  ...   \n",
       "2                    Stripe                 11         Off White  ...   \n",
       "3                     Solid                  9             Black  ...   \n",
       "4                     Solid                 10             White  ...   \n",
       "\n",
       "         index_name index_group_no  index_group_name section_no  \\\n",
       "0        Ladieswear              1        Ladieswear         16   \n",
       "1        Ladieswear              1        Ladieswear         16   \n",
       "2        Ladieswear              1        Ladieswear         16   \n",
       "3  Lingeries/Tights              1        Ladieswear         61   \n",
       "4  Lingeries/Tights              1        Ladieswear         61   \n",
       "\n",
       "             section_name garment_group_no garment_group_name  \\\n",
       "0  Womens Everyday Basics             1002       Jersey Basic   \n",
       "1  Womens Everyday Basics             1002       Jersey Basic   \n",
       "2  Womens Everyday Basics             1002       Jersey Basic   \n",
       "3         Womens Lingerie             1017  Under-, Nightwear   \n",
       "4         Womens Lingerie             1017  Under-, Nightwear   \n",
       "\n",
       "                                         detail_desc  Unnamed: 25 Unnamed: 26  \n",
       "0            Jersey top with narrow shoulder straps.          NaN         NaN  \n",
       "1            Jersey top with narrow shoulder straps.          NaN         NaN  \n",
       "2            Jersey top with narrow shoulder straps.          NaN         NaN  \n",
       "3  Microfibre T-shirt bra with underwired, moulde...          NaN         NaN  \n",
       "4  Microfibre T-shirt bra with underwired, moulde...          NaN         NaN  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9d70131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert customer_id into index to reduce the memory usage\n",
    "Customer_index = customer_df['customer_id'].unique().tolist()\n",
    "\n",
    "customer_to_index_map = {customer: customer_index for customer_index, customer in enumerate(Customer_index)}\n",
    "index_to_customer_map = {customer_index: customer for customer_index, customer in enumerate(Customer_index)}\n",
    "pickle.dump(customer_to_index_map, open(f'customer_to_index_map.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21d86976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the road already has customer_to_index_map.pkl, use this to repeat the result.\n",
    "customer_to_index_map = pickle.load(open(\"customer_to_index_map.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2cc24d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert customer_id to user_id\n",
    "train_df['user_id'] = train_df['customer_id'].map(customer_to_index_map)\n",
    "train_df.drop(['customer_id'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e99714",
   "metadata": {},
   "source": [
    "###### preprocessing article_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bec42a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_article_df(article_df):\n",
    "    # when readjing article information, it misses 0 in the id columns\n",
    "    article_id_df = article_df.apply(lambda x: '0' + str(x[0]), axis = 1)\n",
    "    article_df['article_id'] = article_id_df\n",
    "    article_df.drop(['Unnamed: 25', 'Unnamed: 26'], axis = 1, inplace = True)\n",
    "    # drop some useless columns\n",
    "    article_df = article_df.drop(['graphical_appearance_no','colour_group_code', \\\n",
    "                          'perceived_colour_value_id', 'perceived_colour_master_id',\\\n",
    "                          'department_no', 'index_code', 'index_group_no', 'section_no', \\\n",
    "                          'garment_group_no'], axis = 1)\n",
    "    # combine \"department features\"\n",
    "    article_df['department'] = article_df['department_name'].astype(str) \\\n",
    "                            + '_' + article_df['garment_group_name'].astype(str)\n",
    "    article_df.drop(['department_name', 'garment_group_name'], axis = 1, inplace = True)\n",
    "    # combine \"index features\"\n",
    "    article_df['index_features'] = article_df['index_name'].astype(str) + \\\n",
    "                    '_' + article_df['index_group_name'].astype(str)\n",
    "    article_df.drop(['index_name', 'index_group_name'], axis = 1, inplace = True)\n",
    "    # combine \"color feature\"\n",
    "    article_df['color'] = article_df['colour_group_name'].astype(str) \\\n",
    "                        + '_' + article_df['perceived_colour_value_name'].astype(str) + '_' + \\\n",
    "                        article_df['perceived_colour_master_name'].astype(str)\n",
    "    article_df.drop(['colour_group_name', 'perceived_colour_value_name', \\\n",
    "                  'perceived_colour_master_name'], axis = 1, inplace = True)\n",
    "    # combine \"product features\"\n",
    "    article_df['product_features'] = article_df['product_type_name'].astype(str) + '_' +  \\\n",
    "                             article_df['product_group_name'].astype(str)\n",
    "    article_df.drop(['product_code', 'product_type_no', 'prod_name', \\\n",
    "                             'product_type_name', 'product_group_name'], axis = 1, inplace = True)\n",
    "    # convert all the object variables into category type\n",
    "    categorical_columns = article_df.select_dtypes(include = 'object').columns\n",
    "    for categorical_column in categorical_columns:\n",
    "        article_df[categorical_column] = pd.Categorical(article_df[categorical_column])\n",
    "    # drop detail_desc since it has some null \n",
    "    article_df = article_df.drop('detail_desc', axis = 1)\n",
    "    article_df = article_df.reset_index(drop = True)\n",
    "    return article_df\n",
    "article_df = preprocess_article_df(article_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6867af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the processed dataframe\n",
    "pickle.dump(article_df, open(f'article_df.pkl','wb'))\n",
    "pickle.dump(train_df, open(f'train_df.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc22ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the article_df and train_df\n",
    "article_df = pickle.load(open(\"article_df.pkl\", \"rb\"))\n",
    "train_df = pickle.load(open(\"train_df.pkl\", \"rb\"))\n",
    "'''\n",
    "this is fast when after using the model\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "334c94db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use data after 2020-3-22 to apply EGES\n",
    "transactions = train_df[train_df['t_dat'] >= '2020-03-22']\n",
    "transactions = transactions.merge(article_df, on = 'article_id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dd36c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['t_dat', 'article_id', 'user_id', 'graphical_appearance_name',\n",
       "       'section_name', 'department', 'index_features', 'color',\n",
       "       'product_features'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop 'price', 'sales_channel_id' since they are related to the dynamically changed and could not be used in prediction\n",
    "transactions = transactions.drop(['price', 'sales_channel_id'], axis = 1)\n",
    "transactions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "548283aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_list are the list that used in sparse\n",
    "label_list = ['graphical_appearance_name',\n",
    "              'section_name',\n",
    "              'product_features',\n",
    "              'department',\n",
    "              'index_features',\n",
    "              'color',\n",
    "              'article_id'\n",
    "              ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae90ffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoder\n",
    "lbe_dict = {}\n",
    "\n",
    "# label encoder + 1, in case of padding\n",
    "for target_category_col in label_list:\n",
    "    label_encoder = LabelEncoder()\n",
    "    transactions[target_category_col] = pd.Categorical(transactions[target_category_col])\n",
    "    transactions[target_category_col] = label_encoder.fit_transform(transactions[target_category_col]) + 1\n",
    "    lbe_dict[target_category_col] = label_encoder\n",
    "pickle.dump(lbe_dict, open(f'label_dict.pkl','wb'))\n",
    "pickle.dump(transactions, open(f'transactions.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48d755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbe_dict = pickle.load(open(\"label_dict.pkl\", \"rb\"))\n",
    "transactions = pickle.load(open(\"transactions.pkl\", \"rb\"))\n",
    "'''\n",
    "this is fast when after using the model\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10201fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'graphical_appearance_name': 31,\n",
       " 'section_name': 57,\n",
       " 'product_features': 128,\n",
       " 'department': 244,\n",
       " 'index_features': 11,\n",
       " 'color': 282,\n",
       " 'article_id': 51479}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab_dict is the number of nuniques of each features + 1\n",
    "vocab_dict = {feat:len(lbe_dict[feat].classes_) + 1 for feat in lbe_dict}\n",
    "vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4074d806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51478, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# product is the articles bought in this time periods\n",
    "product = transactions[label_list].drop_duplicates(subset = label_list)\n",
    "product.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3373f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(product, open(f'product.pkl','wb'))\n",
    "pickle.dump(vocab_dict, open(f'vocab_dict.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51ba5e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nthis is fast when after using the model\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the vocab_dict and product\n",
    "\n",
    "product = pickle.load(open(\"product.pkl\", \"rb\"))\n",
    "vocab_dict = pickle.load(open(\"vocab_dict.pkl\", \"rb\"))\n",
    "'''\n",
    "this is fast when after using the model\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fdca08",
   "metadata": {},
   "source": [
    "#### preprocessing on transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87e00a2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transactions['user_id'] = pd.Categorical(transactions['user_id'])\n",
    "transactions['t_dat'] = pd.to_datetime(transactions['t_dat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b060ec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep the goods id in the whole transactions\n",
    "product = product[product['article_id'].isin(set(transactions['article_id']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56ddd5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_counts = Counter(transactions['article_id'].tolist()).items()\n",
    "good_counts = sorted(good_counts, key = lambda x: x[0])\n",
    "counts = np.array([wc[1] for wc in good_counts])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30166358",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(good_counts, open(f'good_counts.pkl', 'wb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bb0cf46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nthis is fast when after using the model\\n\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_counts = pickle.load(open(\"good_counts.pkl\", \"rb\"))\n",
    "'''\n",
    "this is fast when after using the model\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad009a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "0                                               [4104]\n",
       "1    [580, 16128, 34272, 5591, 5591, 5599, 3592, 30...\n",
       "Name: article_id, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corpus = transactions.groupby('user_id')['article_id'].agg(list)\n",
    "df_corpus.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b98f7ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 748053/748053 [00:32<00:00, 23247.93it/s]\n"
     ]
    }
   ],
   "source": [
    "def generate_context_pairs(corpus, window = 5):\n",
    "    \"\"\"\n",
    "    copurs: df_pairs\n",
    "    window: the max distance from center word to side words, in this case articles\n",
    "    \"\"\"\n",
    "    all_pairs = []\n",
    "    for k in tqdm.tqdm(range(len(corpus))):\n",
    "        sent = corpus[k]\n",
    "        if len(sent) < 2: continue\n",
    "        for i in range(len(sent)):\n",
    "            for j in range(max(i - window, 0), min(i + window + 1, len(sent))):\n",
    "                if i!=j:\n",
    "                    all_pairs.append([sent[i], sent[j]])\n",
    "    return all_pairs\n",
    "all_pairs = generate_context_pairs(df_corpus.values, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4cfeadfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62463592, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>580</td>\n",
       "      <td>16128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580</td>\n",
       "      <td>34272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  label\n",
       "0         580  16128\n",
       "1         580  34272"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pair = pd.DataFrame(all_pairs, columns=['article_id', 'label'])\n",
    "print(df_pair.shape)\n",
    "df_pair.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f60a769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>label</th>\n",
       "      <th>graphical_appearance_name</th>\n",
       "      <th>section_name</th>\n",
       "      <th>product_features</th>\n",
       "      <th>department</th>\n",
       "      <th>index_features</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>580</td>\n",
       "      <td>16128</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>99</td>\n",
       "      <td>191</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580</td>\n",
       "      <td>34272</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>99</td>\n",
       "      <td>191</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>580</td>\n",
       "      <td>5591</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>99</td>\n",
       "      <td>191</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>580</td>\n",
       "      <td>5591</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>99</td>\n",
       "      <td>191</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>580</td>\n",
       "      <td>5599</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>99</td>\n",
       "      <td>191</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  label  graphical_appearance_name  section_name  \\\n",
       "0         580  16128                         26            52   \n",
       "1         580  34272                         26            52   \n",
       "2         580   5591                         26            52   \n",
       "3         580   5591                         26            52   \n",
       "4         580   5599                         26            52   \n",
       "\n",
       "   product_features  department  index_features  color  \n",
       "0                99         191               8      8  \n",
       "1                99         191               8      8  \n",
       "2                99         191               8      8  \n",
       "3                99         191               8      8  \n",
       "4                99         191               8      8  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pair = df_pair.merge(product, on = 'article_id', how = 'left')\n",
    "df_pair.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74d82cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair.to_pickle('df_pairs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb99d6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nthis is fast when after using the model\\n\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pair = pickle.load(open(\"df_pairs.pkl\", \"rb\"))\n",
    "'''\n",
    "this is fast when after using the model\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a378ad5",
   "metadata": {},
   "source": [
    "# EGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62dadd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data_cache/'\n",
    "def create_embedding_matrix(sparse_columns, varlen_sparse_columns, embed_dim,\n",
    "                            init_std = 0.0001, padding = True, device = 'cpu', mode = 'mean'):\n",
    "    # sparse_columns => dict{'name':vocab_size}\n",
    "    # Return nn.ModuleDict: for sparse features, {embedding_name: nn.Embedding}\n",
    "    padding_idx = 0 if padding else None\n",
    "    sparse_embedding_dict = {\n",
    "        feat: nn.Embedding(sparse_columns[feat], embed_dim, padding_idx=padding_idx)\n",
    "                             for feat in sparse_columns\n",
    "    }\n",
    "    \n",
    "    if varlen_sparse_columns:\n",
    "        varlen_sparse_embedding_dict = {\n",
    "            feat:nn.EmbeddingBag(varlen_sparse_columns[feat], embed_dim, padding_idx=padding_idx,\n",
    "                                 mode=mode) for feat in varlen_sparse_columns\n",
    "        }\n",
    "        sparse_embedding_dict.update(varlen_sparse_embedding_dict)\n",
    "        \n",
    "    embedding_dict = nn.ModuleDict(sparse_embedding_dict)\n",
    "    \n",
    "    for tensor in embedding_dict.values():\n",
    "        nn.init.normal_(tensor.weight, mean=0, std=init_std)\n",
    "        # nn.init.kaiming_uniform_(tensor.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "    return embedding_dict.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bea2c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EGES(nn.Module):\n",
    "    def __init__(self, sparse_dict, varlen_sparse_dict = None, target_col = 'article_id',\n",
    "                 n_embed = 64, k_side = 6, noise_dist = None, device = 'cpu', padding=True):\n",
    "        \"\"\"sparse_dict: dict, {feature_name: vocab_size}\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.n_embed = n_embed\n",
    "        self.k_side = k_side # number of features (except the id feature)\n",
    "        self.device = device\n",
    "        self.padding = padding\n",
    "        self.target_col = target_col\n",
    "        self.features = list(sparse_dict.keys())\n",
    "        if varlen_sparse_dict:\n",
    "            self.features = self.features + list(varlen_sparse_dict.keys())\n",
    "        self.sample_word_offset = 1 if padding else 0\n",
    "        # input embedding dict, include item and side info\n",
    "        self.input_embedding_dict = create_embedding_matrix(\n",
    "            sparse_dict, varlen_sparse_dict, n_embed,\n",
    "            init_std = 0.0001, padding = padding, device = device, mode = 'mean')\n",
    "        self.out_embed = nn.Embedding(sparse_dict[target_col], n_embed,\n",
    "                                      padding_idx = 0 if padding else None)\n",
    "        self.attn_embed = nn.Embedding(sparse_dict[target_col], k_side + 1, \n",
    "                                       padding_idx = 0 if padding else None)\n",
    "        \n",
    "        # Initialize out embedding tables with uniform distribution\n",
    "        nn.init.normal_(self.out_embed.weight, mean = 0, std = 0.0001)\n",
    "        nn.init.normal_(self.attn_embed.weight, mean = 0, std = 0.0001)\n",
    "\n",
    "        if noise_dist is None:\n",
    "            # sampling words uniformly\n",
    "            self.noise_dist = torch.ones(self.n_vocab)\n",
    "        else:\n",
    "            self.noise_dist = noise_dist\n",
    "        self.noise_dist = self.noise_dist.to(device)\n",
    "\n",
    "    def forward_input(self, input_dict):\n",
    "        # return input vector embeddings\n",
    "        embed_lst = []\n",
    "        for col in self.features:\n",
    "            if col in input_dict:\n",
    "                input_vector = self.input_embedding_dict[col](input_dict[col])\n",
    "                embed_lst.append(input_vector)\n",
    "\n",
    "        batch_size = input_vector.shape[0]\n",
    "        # embeds => [batch_size, k_side+1, n_embed]\n",
    "        embeds = torch.cat(embed_lst, dim = 1).reshape(batch_size, self.k_side + 1, self.n_embed)\n",
    "        \n",
    "        # attation => [batch_size, k_side+1]\n",
    "        attn_w = self.attn_embed(input_dict[self.target_col])\n",
    "        attn_w = torch.exp(attn_w)\n",
    "        attn_s = torch.sum(attn_w, dim = 1).reshape(-1, 1)\n",
    "        attn_w = (attn_w / attn_s).reshape(batch_size, 1, self.k_side + 1) # 归一化\n",
    "        \n",
    "        # attw => [batch_size, 1, k_side+1]\n",
    "        # embeds => [batch_size, k_side+1, embed_size]\n",
    "        # matmul out => [batch_size, 1, embed_size]\n",
    "        input_vector = torch.matmul(attn_w, embeds).squeeze(1)\n",
    "        \n",
    "        return input_vector\n",
    "\n",
    "    def forward_output(self, output_words):\n",
    "        # return output vector embeddings \n",
    "        output_vector = self.out_embed(output_words)\n",
    "        return output_vector\n",
    "    \n",
    "    def forward_noise(self, batch_size, n_samples):\n",
    "        \"\"\"Generate noise vectors with shape [batch_size, n_samples, n_embed]\n",
    "        \"\"\"\n",
    "        # sample words from our noise distribution \n",
    "        noise_words = torch.multinomial(self.noise_dist, batch_size * n_samples, \n",
    "                                        replacement = True) + self.sample_word_offset\n",
    "        noise_vector = self.out_embed(noise_words).view(batch_size, n_samples, self.n_embed)\n",
    "        \n",
    "        return noise_vector\n",
    "    \n",
    "    def forward_cold(self, input_dict):\n",
    "        # return input vector embeddings\n",
    "        embed_lst = []\n",
    "        for col in self.features:\n",
    "            if col in input_dict:\n",
    "                input_vector = self.input_embedding_dict[col](input_dict[col])\n",
    "                embed_lst.append(input_vector)\n",
    "\n",
    "        batch_size = input_vector.shape[0]\n",
    "        # embeds => [batch_size, k_side, n_embed]\n",
    "        embeds = torch.cat(embed_lst, dim = 1).reshape(batch_size, self.k_side, self.n_embed)\n",
    "        return torch.mean(embeds, dim = 1)\n",
    "\n",
    "\n",
    "class NegativeSamplingLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, input_vectors, output_vectors, noise_vectors):\n",
    "        batch_size, embed_size = input_vectors.shape\n",
    "        \n",
    "        # input vectors should be a batch of column vectors\n",
    "        input_vectors = input_vectors.view(batch_size, embed_size, 1)\n",
    "        \n",
    "        # output vectors should be a batch of row vectors\n",
    "        output_vectors = output_vectors.view(batch_size, 1, embed_size)\n",
    "        \n",
    "        # bmm = batch matrix multiplication\n",
    "        # target words log-sigmoid loss\n",
    "        out_loss = torch.bmm(output_vectors, input_vectors).sigmoid().log()\n",
    "        \n",
    "        # negative sampling words log-sigmoid loss\n",
    "        # negative words sigmoid optmize to small, thus here noise_vectors.neg()\n",
    "        noise_loss = torch.bmm(noise_vectors.neg(), input_vectors).sigmoid().log()\n",
    "        # sum the losses over the sample of noise vectors\n",
    "        noise_loss = noise_loss.squeeze().sum(1)\n",
    "        \n",
    "        # sum target and negative loss\n",
    "        return -(out_loss + noise_loss).mean()\n",
    "\n",
    "\n",
    "class TextData(Dataset):\n",
    "    def __init__(self, df, sparse_columns, varlen_sparse_columns = [], device = 'cpu'):\n",
    "        self.sparse_columns = sparse_columns\n",
    "        self.varlen_sparse_columns = varlen_sparse_columns\n",
    "        self.device = device\n",
    "        self.data = {\n",
    "            col:df[col].values for col in sparse_columns\n",
    "        }\n",
    "        if varlen_sparse_columns:\n",
    "            for col in varlen_sparse_columns:\n",
    "                self.data[col] = np.vstack(df[col].values)\n",
    "\n",
    "        self.data_num = len(df)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data_num\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data_dic = {}\n",
    "        for col in self.sparse_columns:\n",
    "            data_dic[col] = torch.tensor(self.data[col][idx]).long() #.to(self.device)\n",
    "        if self.varlen_sparse_columns:\n",
    "            for col in self.varlen_sparse_columns:\n",
    "                data_dic[col] = torch.tensor(self.data[col][idx, :]).long() #.to(self.device)\n",
    "\n",
    "        return data_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "242d7d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.array([wc[1] for wc in good_counts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07d25a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dist = torch.from_numpy(counts ** (0.75) / np.sum(counts ** (0.75)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4dbe1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_columns = ['article_id', 'label', 'graphical_appearance_name', 'section_name', 'department',\\\n",
    "                 'index_features', 'color', 'product_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c4695c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2022 21:51:22 - INFO - __main__ -   Divide 1000/ success\n",
      "05/04/2022 22:02:16 - INFO - __main__ -   Divide 2000/ success\n",
      "05/04/2022 22:12:53 - INFO - __main__ -   Divide 3000/ success\n",
      "05/04/2022 22:23:43 - INFO - __main__ -   Divide 4000/ success\n",
      "05/04/2022 22:34:24 - INFO - __main__ -   Divide 5000/ success\n",
      "05/04/2022 22:44:52 - INFO - __main__ -   Divide 6000/ success\n",
      "05/04/2022 22:47:25 - INFO - __main__ -   Epoch 1/3 Step 6246 Loss = 2.4549567699432373\n",
      "05/04/2022 22:57:53 - INFO - __main__ -   Divide 1000/ success\n",
      "05/04/2022 23:08:18 - INFO - __main__ -   Divide 2000/ success\n",
      "05/04/2022 23:18:45 - INFO - __main__ -   Divide 3000/ success\n",
      "05/04/2022 23:29:38 - INFO - __main__ -   Divide 4000/ success\n",
      "05/04/2022 23:40:07 - INFO - __main__ -   Divide 5000/ success\n",
      "05/04/2022 23:50:29 - INFO - __main__ -   Divide 6000/ success\n",
      "05/04/2022 23:53:01 - INFO - __main__ -   Epoch 2/3 Step 6246 Loss = 2.3850114345550537\n",
      "05/05/2022 00:03:34 - INFO - __main__ -   Divide 1000/ success\n",
      "05/05/2022 00:14:07 - INFO - __main__ -   Divide 2000/ success\n",
      "05/05/2022 00:24:26 - INFO - __main__ -   Divide 3000/ success\n",
      "05/05/2022 00:34:50 - INFO - __main__ -   Divide 4000/ success\n",
      "05/05/2022 00:45:10 - INFO - __main__ -   Divide 5000/ success\n",
      "05/05/2022 00:55:33 - INFO - __main__ -   Divide 6000/ success\n",
      "05/05/2022 00:58:06 - INFO - __main__ -   Epoch 3/3 Step 6246 Loss = 2.388388156890869\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "device = 'gpu'\n",
    "if device == 'gpu' and torch.cuda.is_available():\n",
    "    # print('cuda ready...')\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "textdata = TextData(df_pair, sparse_columns = sparse_columns) \n",
    "textloader = DataLoader(textdata,\n",
    "                        batch_size = 10000,\n",
    "                        shuffle = True,\n",
    "                        num_workers = 0,\n",
    "                        drop_last = False,\n",
    "                        pin_memory = True)\n",
    "\n",
    "embedding_dim_eges = 100\n",
    "model = EGES(vocab_dict, n_embed = embedding_dim_eges, k_side = 6, target_col = 'article_id',\n",
    "             noise_dist = noise_dist, device = device, padding = True).to(device)\n",
    "criterion = NegativeSamplingLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "# optimizer = torch.optim.Adagrad(model.parameters(), lr=0.01)\n",
    "\n",
    "epoch = 3\n",
    "for e in range(epoch):\n",
    "    divide = 0\n",
    "    for i, data_dic in enumerate(textloader):\n",
    "        # input, output and noise vectors\n",
    "        data_dic = {feat:data_dic[feat].to(device) for feat in data_dic}\n",
    "        input_vectors = model.forward_input(data_dic)\n",
    "        output_vectors = model.forward_output(data_dic['label'])\n",
    "        noise_vectors = model.forward_noise(data_dic['label'].shape[0], 10)\n",
    "        # negative sampling loss\n",
    "        loss = criterion(input_vectors, output_vectors, noise_vectors)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        divide += 1\n",
    "        if divide % 1000 == 0:\n",
    "            logger.info(f'Divide {divide}/ success')\n",
    "\n",
    "    logger.info(f'Epoch {e+1}/{epoch} Step {i} Loss = {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aff99f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), f'{DATA_PATH}/model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7161a46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51405, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>label</th>\n",
       "      <th>graphical_appearance_name</th>\n",
       "      <th>section_name</th>\n",
       "      <th>product_features</th>\n",
       "      <th>department</th>\n",
       "      <th>index_features</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>580</td>\n",
       "      <td>16128</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>99</td>\n",
       "      <td>191</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16128</td>\n",
       "      <td>580</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "      <td>191</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  label  graphical_appearance_name  section_name  \\\n",
       "0         580  16128                         26            52   \n",
       "5       16128    580                         26            52   \n",
       "\n",
       "   product_features  department  index_features  color  \n",
       "0                99         191               8      8  \n",
       "5                 9         191               8      8  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the embedding of each item\n",
    "df_item = df_pair.drop_duplicates(subset = ['article_id'])\n",
    "print(df_item.shape)\n",
    "df_item.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0b7c3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "device = 'gpu'\n",
    "if device == 'gpu' and torch.cuda.is_available():\n",
    "    # print('cuda ready...')\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "textdata1 = TextData(df_item, sparse_columns = sparse_columns)\n",
    "textloader1 = DataLoader(textdata1, \n",
    "                         batch_size = 10000, \n",
    "                         shuffle = False, \n",
    "                         drop_last = False, \n",
    "                         pin_memory = True)\n",
    "embedding_dim_eges = 100\n",
    "model = EGES(vocab_dict, n_embed = embedding_dim_eges, k_side = 6, target_col = 'article_id',\n",
    "             noise_dist = noise_dist, device = device, padding = True).to(device)\n",
    "state_dic = torch.load(f'{DATA_PATH}/model.bin')\n",
    "model.load_state_dict(state_dic)\n",
    "model = model.eval()\n",
    "\n",
    "epoch = 3\n",
    "emb_vectors = []\n",
    "with torch.no_grad():\n",
    "    for i, data_dic in enumerate(textloader1):\n",
    "        # input, output and noise vectors\n",
    "        data_dic = {feat:data_dic[feat].to(device) for feat in data_dic}\n",
    "        input_vectors = model.forward_input(data_dic)\n",
    "        emb_vectors.append(input_vectors.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4dfa6855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51405"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_emb = dict(zip(df_item['article_id'].tolist(), np.vstack(emb_vectors)))\n",
    "embed_1 = pd.DataFrame(data = vocab_emb).T.reset_index()\n",
    "embed_1 = embed_1.rename(columns = {'index': 'article_id'})\n",
    "len(vocab_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1f6f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cold_article = transactions[~ transactions['article_id'].isin(embed_1['article_id'])]\n",
    "df_item2 = cold_article.drop_duplicates(subset=['article_id'])[['graphical_appearance_name', \\\n",
    "                                                     'section_name', 'department',\\\n",
    "                                                     'index_features', 'color', 'product_features']]\n",
    "textdata2 = TextData(df_item2, sparse_columns = ['graphical_appearance_name', \\\n",
    "                                                     'section_name', 'department',\\\n",
    "                                                     'index_features', 'color', 'product_features']) \n",
    "textloader2 = DataLoader(textdata2,\n",
    "                        batch_size = 10000,\n",
    "                        shuffle = False,\n",
    "                        drop_last = False,\n",
    "                        pin_memory = True)\n",
    "\n",
    "model = EGES(vocab_dict, n_embed = embedding_dim_eges, k_side = 6, target_col = 'article_id',\n",
    "             noise_dist = noise_dist, device = device, padding = True).to(device)\n",
    "state_dic = torch.load(f'{DATA_PATH}/model.bin')\n",
    "model.load_state_dict(state_dic)\n",
    "model = model.eval()\n",
    "\n",
    "epoch = 3\n",
    "cold_vectors = []\n",
    "with torch.no_grad():\n",
    "    for i, data_dic in enumerate(textloader2):\n",
    "        # input, output and noise vectors\n",
    "        data_dic = {feat:data_dic[feat].to(device) for feat in data_dic}\n",
    "        input_vectors = model.forward_cold(data_dic)\n",
    "        cold_vectors.append(input_vectors.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2257c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cold_emb = dict(zip(cold_article.drop_duplicates(subset = ['article_id'])['article_id'].tolist(), np.vstack(cold_vectors)))\n",
    "embed_2 = pd.DataFrame(data = cold_emb).T.reset_index()\n",
    "embed_2 = embed_2.rename(columns = {'index': 'article_id'})\n",
    "len(cold_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b4183329",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vocab_emb, open(f'vocab_emb.pkl','wb'))\n",
    "pickle.dump(cold_emb, open(f'cold_emb.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96bbbd7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nthis is fast when after using the model\\n\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_emb = pickle.load(open(\"vocab_emb.pkl\", \"rb\"))\n",
    "cold_emb = pickle.load(open(\"cold_emb.pkl\", \"rb\"))\n",
    "'''\n",
    "this is fast when after using the model\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "37115975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51478, 101)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = pd.concat([embed_1, embed_2], axis = 0)\n",
    "embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "81b7c7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(embed, open(f'embed.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e6622bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nthis is fast when after using the model\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = pickle.load(open(\"embed.pkl\", \"rb\"))\n",
    "'''\n",
    "this is fast when after using the model\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e4ad588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>580</td>\n",
       "      <td>0.084992</td>\n",
       "      <td>-0.120273</td>\n",
       "      <td>0.003963</td>\n",
       "      <td>-0.081431</td>\n",
       "      <td>-0.116888</td>\n",
       "      <td>-0.023568</td>\n",
       "      <td>-0.174894</td>\n",
       "      <td>0.103128</td>\n",
       "      <td>0.017729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026659</td>\n",
       "      <td>0.147948</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>-0.230078</td>\n",
       "      <td>0.018663</td>\n",
       "      <td>-0.113092</td>\n",
       "      <td>-0.062846</td>\n",
       "      <td>0.042676</td>\n",
       "      <td>-0.033684</td>\n",
       "      <td>0.087502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16128</td>\n",
       "      <td>0.055172</td>\n",
       "      <td>-0.033577</td>\n",
       "      <td>0.009442</td>\n",
       "      <td>-0.084133</td>\n",
       "      <td>-0.068044</td>\n",
       "      <td>-0.036341</td>\n",
       "      <td>-0.103877</td>\n",
       "      <td>0.088267</td>\n",
       "      <td>-0.008914</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007283</td>\n",
       "      <td>0.137015</td>\n",
       "      <td>0.032505</td>\n",
       "      <td>-0.141099</td>\n",
       "      <td>0.036039</td>\n",
       "      <td>-0.196943</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>0.098618</td>\n",
       "      <td>-0.005751</td>\n",
       "      <td>0.048917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34272</td>\n",
       "      <td>0.088780</td>\n",
       "      <td>-0.073143</td>\n",
       "      <td>-0.063883</td>\n",
       "      <td>0.054561</td>\n",
       "      <td>0.059336</td>\n",
       "      <td>-0.081845</td>\n",
       "      <td>0.059603</td>\n",
       "      <td>-0.139398</td>\n",
       "      <td>-0.105134</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035409</td>\n",
       "      <td>0.003863</td>\n",
       "      <td>0.023866</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>-0.003376</td>\n",
       "      <td>0.093379</td>\n",
       "      <td>-0.027540</td>\n",
       "      <td>-0.091256</td>\n",
       "      <td>-0.060654</td>\n",
       "      <td>0.043634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5591</td>\n",
       "      <td>0.022267</td>\n",
       "      <td>-0.161352</td>\n",
       "      <td>0.018141</td>\n",
       "      <td>0.012872</td>\n",
       "      <td>0.112759</td>\n",
       "      <td>0.028385</td>\n",
       "      <td>-0.096220</td>\n",
       "      <td>0.130043</td>\n",
       "      <td>0.102090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024699</td>\n",
       "      <td>0.216010</td>\n",
       "      <td>-0.019542</td>\n",
       "      <td>-0.090856</td>\n",
       "      <td>0.068689</td>\n",
       "      <td>-0.108800</td>\n",
       "      <td>0.022696</td>\n",
       "      <td>0.093130</td>\n",
       "      <td>0.031740</td>\n",
       "      <td>0.112459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5599</td>\n",
       "      <td>0.006237</td>\n",
       "      <td>-0.131394</td>\n",
       "      <td>-0.019968</td>\n",
       "      <td>0.039123</td>\n",
       "      <td>0.081398</td>\n",
       "      <td>-0.125605</td>\n",
       "      <td>-0.125922</td>\n",
       "      <td>0.041584</td>\n",
       "      <td>0.110282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106852</td>\n",
       "      <td>0.215627</td>\n",
       "      <td>0.048003</td>\n",
       "      <td>-0.004737</td>\n",
       "      <td>0.010335</td>\n",
       "      <td>0.040623</td>\n",
       "      <td>0.028842</td>\n",
       "      <td>0.018428</td>\n",
       "      <td>0.005410</td>\n",
       "      <td>0.127457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>28318</td>\n",
       "      <td>0.011530</td>\n",
       "      <td>-0.044742</td>\n",
       "      <td>0.002643</td>\n",
       "      <td>-0.011702</td>\n",
       "      <td>0.091530</td>\n",
       "      <td>-0.037206</td>\n",
       "      <td>-0.016242</td>\n",
       "      <td>0.066128</td>\n",
       "      <td>0.023217</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017675</td>\n",
       "      <td>-0.031758</td>\n",
       "      <td>0.059508</td>\n",
       "      <td>0.005869</td>\n",
       "      <td>0.013107</td>\n",
       "      <td>-0.189967</td>\n",
       "      <td>-0.009812</td>\n",
       "      <td>0.027702</td>\n",
       "      <td>0.037468</td>\n",
       "      <td>0.141796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>23392</td>\n",
       "      <td>0.067459</td>\n",
       "      <td>-0.272700</td>\n",
       "      <td>-0.124268</td>\n",
       "      <td>-0.135245</td>\n",
       "      <td>-0.057184</td>\n",
       "      <td>-0.217716</td>\n",
       "      <td>-0.142877</td>\n",
       "      <td>0.260113</td>\n",
       "      <td>-0.021388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106918</td>\n",
       "      <td>-0.163500</td>\n",
       "      <td>0.193337</td>\n",
       "      <td>-0.124138</td>\n",
       "      <td>0.162893</td>\n",
       "      <td>-0.508588</td>\n",
       "      <td>0.244683</td>\n",
       "      <td>-0.177073</td>\n",
       "      <td>0.164317</td>\n",
       "      <td>-0.086847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>50497</td>\n",
       "      <td>0.243048</td>\n",
       "      <td>-0.035740</td>\n",
       "      <td>-0.091096</td>\n",
       "      <td>0.140926</td>\n",
       "      <td>-0.088643</td>\n",
       "      <td>0.022642</td>\n",
       "      <td>-0.043034</td>\n",
       "      <td>0.011003</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043488</td>\n",
       "      <td>-0.159995</td>\n",
       "      <td>0.158959</td>\n",
       "      <td>0.127475</td>\n",
       "      <td>0.118843</td>\n",
       "      <td>-0.187187</td>\n",
       "      <td>0.058009</td>\n",
       "      <td>0.130073</td>\n",
       "      <td>-0.149105</td>\n",
       "      <td>0.024234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>48844</td>\n",
       "      <td>0.022625</td>\n",
       "      <td>0.115115</td>\n",
       "      <td>-0.038445</td>\n",
       "      <td>0.008991</td>\n",
       "      <td>0.056205</td>\n",
       "      <td>-0.019346</td>\n",
       "      <td>0.052624</td>\n",
       "      <td>0.079166</td>\n",
       "      <td>0.119205</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005914</td>\n",
       "      <td>0.195732</td>\n",
       "      <td>0.041930</td>\n",
       "      <td>0.022495</td>\n",
       "      <td>0.053857</td>\n",
       "      <td>-0.074148</td>\n",
       "      <td>0.088767</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.186994</td>\n",
       "      <td>0.192870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>38692</td>\n",
       "      <td>-0.049917</td>\n",
       "      <td>-0.009530</td>\n",
       "      <td>0.024932</td>\n",
       "      <td>0.092619</td>\n",
       "      <td>-0.090117</td>\n",
       "      <td>-0.145434</td>\n",
       "      <td>0.147361</td>\n",
       "      <td>0.124562</td>\n",
       "      <td>0.101307</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016649</td>\n",
       "      <td>-0.122265</td>\n",
       "      <td>-0.112890</td>\n",
       "      <td>-0.077277</td>\n",
       "      <td>-0.227963</td>\n",
       "      <td>0.182490</td>\n",
       "      <td>0.052601</td>\n",
       "      <td>-0.153091</td>\n",
       "      <td>0.280339</td>\n",
       "      <td>0.216250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51478 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    article_id         0         1         2         3         4         5  \\\n",
       "0          580  0.084992 -0.120273  0.003963 -0.081431 -0.116888 -0.023568   \n",
       "1        16128  0.055172 -0.033577  0.009442 -0.084133 -0.068044 -0.036341   \n",
       "2        34272  0.088780 -0.073143 -0.063883  0.054561  0.059336 -0.081845   \n",
       "3         5591  0.022267 -0.161352  0.018141  0.012872  0.112759  0.028385   \n",
       "4         5599  0.006237 -0.131394 -0.019968  0.039123  0.081398 -0.125605   \n",
       "..         ...       ...       ...       ...       ...       ...       ...   \n",
       "68       28318  0.011530 -0.044742  0.002643 -0.011702  0.091530 -0.037206   \n",
       "69       23392  0.067459 -0.272700 -0.124268 -0.135245 -0.057184 -0.217716   \n",
       "70       50497  0.243048 -0.035740 -0.091096  0.140926 -0.088643  0.022642   \n",
       "71       48844  0.022625  0.115115 -0.038445  0.008991  0.056205 -0.019346   \n",
       "72       38692 -0.049917 -0.009530  0.024932  0.092619 -0.090117 -0.145434   \n",
       "\n",
       "           6         7         8  ...        90        91        92        93  \\\n",
       "0  -0.174894  0.103128  0.017729  ...  0.026659  0.147948  0.001756 -0.230078   \n",
       "1  -0.103877  0.088267 -0.008914  ... -0.007283  0.137015  0.032505 -0.141099   \n",
       "2   0.059603 -0.139398 -0.105134  ... -0.035409  0.003863  0.023866  0.002993   \n",
       "3  -0.096220  0.130043  0.102090  ... -0.024699  0.216010 -0.019542 -0.090856   \n",
       "4  -0.125922  0.041584  0.110282  ...  0.106852  0.215627  0.048003 -0.004737   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "68 -0.016242  0.066128  0.023217  ... -0.017675 -0.031758  0.059508  0.005869   \n",
       "69 -0.142877  0.260113 -0.021388  ...  0.106918 -0.163500  0.193337 -0.124138   \n",
       "70 -0.043034  0.011003  0.090474  ...  0.043488 -0.159995  0.158959  0.127475   \n",
       "71  0.052624  0.079166  0.119205  ... -0.005914  0.195732  0.041930  0.022495   \n",
       "72  0.147361  0.124562  0.101307  ... -0.016649 -0.122265 -0.112890 -0.077277   \n",
       "\n",
       "          94        95        96        97        98        99  \n",
       "0   0.018663 -0.113092 -0.062846  0.042676 -0.033684  0.087502  \n",
       "1   0.036039 -0.196943  0.002166  0.098618 -0.005751  0.048917  \n",
       "2  -0.003376  0.093379 -0.027540 -0.091256 -0.060654  0.043634  \n",
       "3   0.068689 -0.108800  0.022696  0.093130  0.031740  0.112459  \n",
       "4   0.010335  0.040623  0.028842  0.018428  0.005410  0.127457  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "68  0.013107 -0.189967 -0.009812  0.027702  0.037468  0.141796  \n",
       "69  0.162893 -0.508588  0.244683 -0.177073  0.164317 -0.086847  \n",
       "70  0.118843 -0.187187  0.058009  0.130073 -0.149105  0.024234  \n",
       "71  0.053857 -0.074148  0.088767  0.260374  0.186994  0.192870  \n",
       "72 -0.227963  0.182490  0.052601 -0.153091  0.280339  0.216250  \n",
       "\n",
       "[51478 rows x 101 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2804f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sub_customer_id = sub_df.customer_id.map(customer_to_index_map)\n",
    "sub_customer = sub_df.customer_id\n",
    "embed_matrix = np.array(embed.sort_values('article_id').set_index('article_id'))\n",
    "df_corpus_pd = pd.DataFrame(df_corpus)\n",
    "customer_id_list = []\n",
    "pred_id_list = []\n",
    "for index, row in tqdm.tqdm(df_corpus_pd.iterrows()):\n",
    "    customer_id = index\n",
    "    item_list_ = row[0]\n",
    "    sim_ = np.zeros((1, embed.shape[0]))\n",
    "    len_sim_ = len(sim_)\n",
    "    for item_ in item_list_:\n",
    "        sim_ += cosine_similarity(embed_matrix[item_ - 1].reshape(1, embedding_dim_eges), embed_matrix)\n",
    "    sorted_sim_index_ = np.argsort(sim_)[0]\n",
    "    pred_list = sorted_sim_index_[len(sorted_sim_index_) - 12 - len_sim_:len(sorted_sim_index_) - len_sim_]\n",
    "    result_list = [lbe_dict['article_id'].inverse_transform([item_id])[0] for item_id in pred_list]\n",
    "    preds = ' '.join(result_list)\n",
    "    customer_id_list.append(sub_customer[customer_id])\n",
    "    pred_id_list.append(preds)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e5ac5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import reco\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30ac9db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions[\"t_dat\"] = pd.to_datetime(transactions[\"t_dat\"])\n",
    "train1 = transactions[(transactions[\"t_dat\"] >= datetime.datetime(2020,8,23)) & (transactions['t_dat'] < datetime.datetime(2020,9,23))]\n",
    "train2 = transactions[(transactions[\"t_dat\"] >= datetime.datetime(2020,7,23)) & (transactions['t_dat'] < datetime.datetime(2020,8,23))]\n",
    "train3 = transactions[(transactions[\"t_dat\"] >= datetime.datetime(2020,6,23)) & (transactions['t_dat'] < datetime.datetime(2020,7,23))]\n",
    "train4 = transactions[(transactions[\"t_dat\"] >= datetime.datetime(2020,5,23)) & (transactions['t_dat'] < datetime.datetime(2020,6,23))]\n",
    "# trainx is the month dataset\n",
    "positive_items_per_user1 = train1.groupby(['user_id'])['article_id'].apply(list)\n",
    "positive_items_per_user2 = train2.groupby(['user_id'])['article_id'].apply(list)\n",
    "positive_items_per_user3 = train3.groupby(['user_id'])['article_id'].apply(list)\n",
    "positive_items_per_user4 = train4.groupby(['user_id'])['article_id'].apply(list)\n",
    "# positive_items_per_userx is each basket of the user in each dataset trainx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d0e7642",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train1, train2, train3, train4], axis = 0)[['t_dat', 'article_id', 'user_id']]\n",
    "train['pop_factor'] = train['t_dat'].apply(lambda x: 1/((datetime.datetime(2020,9,23) - x).days // 7 + 1)**2)\n",
    "# in this case, we give the popular index by using the week away from the end of the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea567276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# purchase count of each article\n",
    "items_total_count = train.groupby(['article_id'])['article_id'].count()\n",
    "# purchase count of each user\n",
    "users_total_count = train.groupby(['user_id'])['user_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e52e893",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['feedback'] = 1\n",
    "train = train.groupby(['user_id', 'article_id']).sum().reset_index()\n",
    "train['feedback'] = train.apply(lambda row: row['feedback']/popular_items_group[row['article_id']], axis=1)\n",
    "\n",
    "train['feedback'] = train['feedback'].apply(lambda x: 5.0 if x > 5.0 else x)\n",
    "train = train.sample(frac= 1).reset_index(drop=True)\n",
    "train['feedback'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f71ca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35d8b679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nthis is fast when after using the model\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv') \n",
    "'''\n",
    "this is fast when after using the model\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0750fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the popular items in the last month, for using in the cold recommendation\n",
    "train_ = transactions[(transactions[\"t_dat\"] >= datetime.datetime(2020,9,1)) & (transactions['t_dat'] < datetime.datetime(2020,9,23))]\n",
    "train_['pop_factor'] = train_['t_dat'].apply(lambda x: 1/(datetime.datetime(2020,9,23) - x).days)\n",
    "popular_items_factor = train_.groupby(['article_id'])['pop_factor'].sum()\n",
    "\n",
    "_, popular_items = zip(*sorted(zip(popular_items_factor, popular_items_factor.keys()))[::-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c47612c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_purchase_list = train_.groupby(['user_id'])['article_id'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c73918e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_train = train.merge(embed, on = 'article_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bceb30ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>pop_factor</th>\n",
       "      <th>feedback</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1171987</td>\n",
       "      <td>4912</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.462161</td>\n",
       "      <td>0.077948</td>\n",
       "      <td>-0.096497</td>\n",
       "      <td>-0.105586</td>\n",
       "      <td>-0.140482</td>\n",
       "      <td>0.158139</td>\n",
       "      <td>0.037315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078302</td>\n",
       "      <td>0.192526</td>\n",
       "      <td>0.033189</td>\n",
       "      <td>-0.071227</td>\n",
       "      <td>-0.087542</td>\n",
       "      <td>-0.064278</td>\n",
       "      <td>-0.045917</td>\n",
       "      <td>0.122057</td>\n",
       "      <td>-0.040464</td>\n",
       "      <td>-0.072226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1244641</td>\n",
       "      <td>44577</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>3.491993</td>\n",
       "      <td>-0.013230</td>\n",
       "      <td>-0.292907</td>\n",
       "      <td>0.155605</td>\n",
       "      <td>-0.023271</td>\n",
       "      <td>-0.011968</td>\n",
       "      <td>0.102960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112035</td>\n",
       "      <td>0.057561</td>\n",
       "      <td>-0.077107</td>\n",
       "      <td>-0.185574</td>\n",
       "      <td>0.117108</td>\n",
       "      <td>0.103868</td>\n",
       "      <td>0.133962</td>\n",
       "      <td>-0.092365</td>\n",
       "      <td>-0.056927</td>\n",
       "      <td>-0.113168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>515438</td>\n",
       "      <td>30464</td>\n",
       "      <td>0.006920</td>\n",
       "      <td>1.357951</td>\n",
       "      <td>0.069534</td>\n",
       "      <td>-0.173100</td>\n",
       "      <td>-0.065951</td>\n",
       "      <td>0.080157</td>\n",
       "      <td>0.076465</td>\n",
       "      <td>0.118090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120119</td>\n",
       "      <td>0.062567</td>\n",
       "      <td>-0.064975</td>\n",
       "      <td>-0.145845</td>\n",
       "      <td>0.035075</td>\n",
       "      <td>-0.003932</td>\n",
       "      <td>0.087852</td>\n",
       "      <td>0.093500</td>\n",
       "      <td>-0.012367</td>\n",
       "      <td>-0.003430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>612287</td>\n",
       "      <td>39851</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.030483</td>\n",
       "      <td>-0.008250</td>\n",
       "      <td>-0.088505</td>\n",
       "      <td>-0.030072</td>\n",
       "      <td>-0.008646</td>\n",
       "      <td>-0.096147</td>\n",
       "      <td>-0.102708</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093137</td>\n",
       "      <td>-0.009940</td>\n",
       "      <td>0.006413</td>\n",
       "      <td>-0.107907</td>\n",
       "      <td>-0.115632</td>\n",
       "      <td>-0.214477</td>\n",
       "      <td>-0.056602</td>\n",
       "      <td>0.019968</td>\n",
       "      <td>0.040323</td>\n",
       "      <td>0.131809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1229373</td>\n",
       "      <td>19563</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>0.118781</td>\n",
       "      <td>-0.088854</td>\n",
       "      <td>-0.027735</td>\n",
       "      <td>0.049713</td>\n",
       "      <td>-0.199672</td>\n",
       "      <td>0.026638</td>\n",
       "      <td>0.037173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031147</td>\n",
       "      <td>0.223270</td>\n",
       "      <td>0.121350</td>\n",
       "      <td>-0.097440</td>\n",
       "      <td>-0.053039</td>\n",
       "      <td>-0.068055</td>\n",
       "      <td>-0.121871</td>\n",
       "      <td>-0.017136</td>\n",
       "      <td>-0.004563</td>\n",
       "      <td>0.006760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4963867</th>\n",
       "      <td>198142</td>\n",
       "      <td>6115</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.037444</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.045489</td>\n",
       "      <td>-0.028387</td>\n",
       "      <td>-0.092784</td>\n",
       "      <td>-0.096198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027728</td>\n",
       "      <td>-0.180711</td>\n",
       "      <td>0.039535</td>\n",
       "      <td>-0.074382</td>\n",
       "      <td>0.020917</td>\n",
       "      <td>-0.100065</td>\n",
       "      <td>-0.085434</td>\n",
       "      <td>0.075915</td>\n",
       "      <td>0.008848</td>\n",
       "      <td>0.125217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4963868</th>\n",
       "      <td>1265130</td>\n",
       "      <td>4402</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>0.036688</td>\n",
       "      <td>0.043992</td>\n",
       "      <td>-0.172384</td>\n",
       "      <td>-0.033499</td>\n",
       "      <td>-0.048964</td>\n",
       "      <td>0.020837</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.141494</td>\n",
       "      <td>-0.141102</td>\n",
       "      <td>-0.014078</td>\n",
       "      <td>-0.094602</td>\n",
       "      <td>-0.136878</td>\n",
       "      <td>-0.092220</td>\n",
       "      <td>0.048717</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.058695</td>\n",
       "      <td>0.099959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4963869</th>\n",
       "      <td>612547</td>\n",
       "      <td>28919</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.026352</td>\n",
       "      <td>0.028164</td>\n",
       "      <td>0.049544</td>\n",
       "      <td>-0.004918</td>\n",
       "      <td>-0.026713</td>\n",
       "      <td>-0.215829</td>\n",
       "      <td>-0.045707</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028205</td>\n",
       "      <td>0.255497</td>\n",
       "      <td>-0.027412</td>\n",
       "      <td>-0.033971</td>\n",
       "      <td>-0.032903</td>\n",
       "      <td>-0.410007</td>\n",
       "      <td>0.120757</td>\n",
       "      <td>0.070377</td>\n",
       "      <td>0.143795</td>\n",
       "      <td>-0.095313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4963870</th>\n",
       "      <td>991889</td>\n",
       "      <td>36286</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.108753</td>\n",
       "      <td>0.049940</td>\n",
       "      <td>-0.105382</td>\n",
       "      <td>-0.056156</td>\n",
       "      <td>0.032200</td>\n",
       "      <td>0.029715</td>\n",
       "      <td>0.018723</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034555</td>\n",
       "      <td>0.230959</td>\n",
       "      <td>0.122061</td>\n",
       "      <td>-0.039744</td>\n",
       "      <td>-0.026802</td>\n",
       "      <td>0.079542</td>\n",
       "      <td>0.051358</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>-0.033647</td>\n",
       "      <td>0.077619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4963871</th>\n",
       "      <td>512349</td>\n",
       "      <td>39869</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>0.138135</td>\n",
       "      <td>0.056214</td>\n",
       "      <td>-0.118101</td>\n",
       "      <td>-0.095288</td>\n",
       "      <td>0.019548</td>\n",
       "      <td>-0.045778</td>\n",
       "      <td>0.027185</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071210</td>\n",
       "      <td>0.127198</td>\n",
       "      <td>0.049127</td>\n",
       "      <td>-0.079090</td>\n",
       "      <td>0.005229</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>-0.020602</td>\n",
       "      <td>0.025928</td>\n",
       "      <td>0.087301</td>\n",
       "      <td>-0.030397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4963872 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  article_id  pop_factor  feedback         0         1  \\\n",
       "0        1171987        4912    0.004444  0.462161  0.077948 -0.096497   \n",
       "1        1244641       44577    0.250000  3.491993 -0.013230 -0.292907   \n",
       "2         515438       30464    0.006920  1.357951  0.069534 -0.173100   \n",
       "3         612287       39851    0.005102  0.030483 -0.008250 -0.088505   \n",
       "4        1229373       19563    0.005917  0.118781 -0.088854 -0.027735   \n",
       "...          ...         ...         ...       ...       ...       ...   \n",
       "4963867   198142        6115    0.015625  0.002992  0.037444  0.025391   \n",
       "4963868  1265130        4402    0.111111  0.002547  0.036688  0.043992   \n",
       "4963869   612547       28919    0.003906  0.026352  0.028164  0.049544   \n",
       "4963870   991889       36286    0.062500  0.108753  0.049940 -0.105382   \n",
       "4963871   512349       39869    0.003460  0.138135  0.056214 -0.118101   \n",
       "\n",
       "                2         3         4         5  ...        90        91  \\\n",
       "0       -0.105586 -0.140482  0.158139  0.037315  ... -0.078302  0.192526   \n",
       "1        0.155605 -0.023271 -0.011968  0.102960  ... -0.112035  0.057561   \n",
       "2       -0.065951  0.080157  0.076465  0.118090  ... -0.120119  0.062567   \n",
       "3       -0.030072 -0.008646 -0.096147 -0.102708  ... -0.093137 -0.009940   \n",
       "4        0.049713 -0.199672  0.026638  0.037173  ...  0.031147  0.223270   \n",
       "...           ...       ...       ...       ...  ...       ...       ...   \n",
       "4963867  0.045489 -0.028387 -0.092784 -0.096198  ... -0.027728 -0.180711   \n",
       "4963868 -0.172384 -0.033499 -0.048964  0.020837  ... -0.141494 -0.141102   \n",
       "4963869 -0.004918 -0.026713 -0.215829 -0.045707  ... -0.028205  0.255497   \n",
       "4963870 -0.056156  0.032200  0.029715  0.018723  ... -0.034555  0.230959   \n",
       "4963871 -0.095288  0.019548 -0.045778  0.027185  ... -0.071210  0.127198   \n",
       "\n",
       "               92        93        94        95        96        97        98  \\\n",
       "0        0.033189 -0.071227 -0.087542 -0.064278 -0.045917  0.122057 -0.040464   \n",
       "1       -0.077107 -0.185574  0.117108  0.103868  0.133962 -0.092365 -0.056927   \n",
       "2       -0.064975 -0.145845  0.035075 -0.003932  0.087852  0.093500 -0.012367   \n",
       "3        0.006413 -0.107907 -0.115632 -0.214477 -0.056602  0.019968  0.040323   \n",
       "4        0.121350 -0.097440 -0.053039 -0.068055 -0.121871 -0.017136 -0.004563   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "4963867  0.039535 -0.074382  0.020917 -0.100065 -0.085434  0.075915  0.008848   \n",
       "4963868 -0.014078 -0.094602 -0.136878 -0.092220  0.048717  0.000024  0.058695   \n",
       "4963869 -0.027412 -0.033971 -0.032903 -0.410007  0.120757  0.070377  0.143795   \n",
       "4963870  0.122061 -0.039744 -0.026802  0.079542  0.051358  0.044519 -0.033647   \n",
       "4963871  0.049127 -0.079090  0.005229 -0.000124 -0.020602  0.025928  0.087301   \n",
       "\n",
       "               99  \n",
       "0       -0.072226  \n",
       "1       -0.113168  \n",
       "2       -0.003430  \n",
       "3        0.131809  \n",
       "4        0.006760  \n",
       "...           ...  \n",
       "4963867  0.125217  \n",
       "4963868  0.099959  \n",
       "4963869 -0.095313  \n",
       "4963870  0.077619  \n",
       "4963871 -0.030397  \n",
       "\n",
       "[4963872 rows x 104 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6d2c306",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(fm_train, open(f'fm_train.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0886322",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_train = pickle.load(open(\"fm_train.pkl\", \"rb\"))\n",
    "'''\n",
    "this is fast when after using the model\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f024399",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_x = fm_train.drop(['feedback', 'pop_factor'], axis = 1)\n",
    "fm_y = fm_train['feedback']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6eec48de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_x.article_id = fm_x.article_id.astype('str')\n",
    "fm_x.user_id = fm_x.user_id.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3bd7ef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reco.recommender import FM\n",
    "fm_model = FM(k = 10, learning_rate = 0.005, regularizer = .005, iterations = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "75f4b00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 time 804.7702125999999 mse 1.8785846014008838\n"
     ]
    }
   ],
   "source": [
    "fm_model.fit(X = fm_x, y = fm_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f30dee9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_items = list(popular_items)\n",
    "outputs = []\n",
    "cnt = 0\n",
    "user_predict = []\n",
    "user = 1371960\n",
    "most_common_items_of_user = {article_id: time for article_id, time in Counter(positive_items_per_user1[user]).most_common()}\n",
    "# most_common_items_of_user is used to get the most frequently bought article by user\n",
    "predict_df = embed.loc[embed.article_id.isin(list(most_common_items_of_user.keys())), :]\n",
    "predict_df['user_id'] = str(user)\n",
    "predict_df.article_id = predict_df.article_id.astype('str')\n",
    "predict_df = predict_df[['user_id', 'article_id'] + list(range(100))]\n",
    "fm_model.predict(predict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "49abc0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1371960</td>\n",
       "      <td>16128</td>\n",
       "      <td>0.055172</td>\n",
       "      <td>-0.033577</td>\n",
       "      <td>0.009442</td>\n",
       "      <td>-0.084133</td>\n",
       "      <td>-0.068044</td>\n",
       "      <td>-0.036341</td>\n",
       "      <td>-0.103877</td>\n",
       "      <td>0.088267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007283</td>\n",
       "      <td>0.137015</td>\n",
       "      <td>0.032505</td>\n",
       "      <td>-0.141099</td>\n",
       "      <td>0.036039</td>\n",
       "      <td>-0.196943</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>0.098618</td>\n",
       "      <td>-0.005751</td>\n",
       "      <td>0.048917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1371960</td>\n",
       "      <td>28040</td>\n",
       "      <td>0.285456</td>\n",
       "      <td>-0.012846</td>\n",
       "      <td>-0.025513</td>\n",
       "      <td>-0.107498</td>\n",
       "      <td>0.061365</td>\n",
       "      <td>-0.122001</td>\n",
       "      <td>-0.007056</td>\n",
       "      <td>-0.329416</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175180</td>\n",
       "      <td>0.009281</td>\n",
       "      <td>0.084295</td>\n",
       "      <td>0.208447</td>\n",
       "      <td>-0.086410</td>\n",
       "      <td>-0.165863</td>\n",
       "      <td>0.279223</td>\n",
       "      <td>0.288356</td>\n",
       "      <td>0.110291</td>\n",
       "      <td>-0.069078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1371960</td>\n",
       "      <td>5599</td>\n",
       "      <td>0.006237</td>\n",
       "      <td>-0.131394</td>\n",
       "      <td>-0.019968</td>\n",
       "      <td>0.039123</td>\n",
       "      <td>0.081398</td>\n",
       "      <td>-0.125605</td>\n",
       "      <td>-0.125922</td>\n",
       "      <td>0.041584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106852</td>\n",
       "      <td>0.215627</td>\n",
       "      <td>0.048003</td>\n",
       "      <td>-0.004737</td>\n",
       "      <td>0.010335</td>\n",
       "      <td>0.040623</td>\n",
       "      <td>0.028842</td>\n",
       "      <td>0.018428</td>\n",
       "      <td>0.005410</td>\n",
       "      <td>0.127457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1371960</td>\n",
       "      <td>26459</td>\n",
       "      <td>0.181629</td>\n",
       "      <td>-0.077577</td>\n",
       "      <td>-0.196139</td>\n",
       "      <td>0.165459</td>\n",
       "      <td>0.161856</td>\n",
       "      <td>-0.114184</td>\n",
       "      <td>-0.132380</td>\n",
       "      <td>-0.273783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056080</td>\n",
       "      <td>-0.165378</td>\n",
       "      <td>-0.003228</td>\n",
       "      <td>-0.269450</td>\n",
       "      <td>-0.214114</td>\n",
       "      <td>0.091695</td>\n",
       "      <td>0.172464</td>\n",
       "      <td>-0.082990</td>\n",
       "      <td>0.238170</td>\n",
       "      <td>0.358174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1371960</td>\n",
       "      <td>31011</td>\n",
       "      <td>0.109880</td>\n",
       "      <td>-0.148156</td>\n",
       "      <td>-0.022366</td>\n",
       "      <td>-0.060636</td>\n",
       "      <td>0.065297</td>\n",
       "      <td>-0.113259</td>\n",
       "      <td>-0.145037</td>\n",
       "      <td>0.071251</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004872</td>\n",
       "      <td>0.220249</td>\n",
       "      <td>0.054002</td>\n",
       "      <td>0.029841</td>\n",
       "      <td>0.070581</td>\n",
       "      <td>-0.088684</td>\n",
       "      <td>0.048450</td>\n",
       "      <td>0.003894</td>\n",
       "      <td>-0.000620</td>\n",
       "      <td>0.078128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1371960</td>\n",
       "      <td>31842</td>\n",
       "      <td>0.146689</td>\n",
       "      <td>-0.086021</td>\n",
       "      <td>-0.105034</td>\n",
       "      <td>0.077244</td>\n",
       "      <td>-0.121281</td>\n",
       "      <td>-0.150452</td>\n",
       "      <td>-0.004122</td>\n",
       "      <td>0.117337</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006609</td>\n",
       "      <td>-0.330679</td>\n",
       "      <td>0.006371</td>\n",
       "      <td>0.099013</td>\n",
       "      <td>0.044259</td>\n",
       "      <td>-0.078815</td>\n",
       "      <td>-0.054333</td>\n",
       "      <td>0.100142</td>\n",
       "      <td>0.052132</td>\n",
       "      <td>-0.090567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id article_id         0         1         2         3         4  \\\n",
       "1  1371960      16128  0.055172 -0.033577  0.009442 -0.084133 -0.068044   \n",
       "1  1371960      28040  0.285456 -0.012846 -0.025513 -0.107498  0.061365   \n",
       "4  1371960       5599  0.006237 -0.131394 -0.019968  0.039123  0.081398   \n",
       "4  1371960      26459  0.181629 -0.077577 -0.196139  0.165459  0.161856   \n",
       "7  1371960      31011  0.109880 -0.148156 -0.022366 -0.060636  0.065297   \n",
       "7  1371960      31842  0.146689 -0.086021 -0.105034  0.077244 -0.121281   \n",
       "\n",
       "          5         6         7  ...        90        91        92        93  \\\n",
       "1 -0.036341 -0.103877  0.088267  ... -0.007283  0.137015  0.032505 -0.141099   \n",
       "1 -0.122001 -0.007056 -0.329416  ... -0.175180  0.009281  0.084295  0.208447   \n",
       "4 -0.125605 -0.125922  0.041584  ...  0.106852  0.215627  0.048003 -0.004737   \n",
       "4 -0.114184 -0.132380 -0.273783  ...  0.056080 -0.165378 -0.003228 -0.269450   \n",
       "7 -0.113259 -0.145037  0.071251  ... -0.004872  0.220249  0.054002  0.029841   \n",
       "7 -0.150452 -0.004122  0.117337  ... -0.006609 -0.330679  0.006371  0.099013   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "1  0.036039 -0.196943  0.002166  0.098618 -0.005751  0.048917  \n",
       "1 -0.086410 -0.165863  0.279223  0.288356  0.110291 -0.069078  \n",
       "4  0.010335  0.040623  0.028842  0.018428  0.005410  0.127457  \n",
       "4 -0.214114  0.091695  0.172464 -0.082990  0.238170  0.358174  \n",
       "7  0.070581 -0.088684  0.048450  0.003894 -0.000620  0.078128  \n",
       "7  0.044259 -0.078815 -0.054333  0.100142  0.052132 -0.090567  \n",
       "\n",
       "[6 rows x 102 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095162c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pickle.dump(customer_id_list, open(f'customer_id_list.pkl','wb'))\n",
    "pickle.dump(pred_id_list, open(f'pred_id_list.pkl','wb'))\n",
    "customer_id_list = pickle.load(open(\"customer_id_list.pkl\", \"rb\"))\n",
    "pred_id_list = pickle.load(open(\"pred_id_list.pkl\", \"rb\"))\n",
    "'''\n",
    "'''\n",
    "this is fast when after using the model\n",
    "\n",
    "'''\n",
    "'''\n",
    "sub_pred_df_1 = pd.DataFrame({'customer_id': customer_id_list, 'prediction': pred_id_list})\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793bbfed",
   "metadata": {},
   "source": [
    "## preprocess customer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac068c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_customer_df(customer_df):\n",
    "    # change customer_id to user_id in customer information dataframe\n",
    "    customer_df['user_id'] = customer_df['customer_id'].map(customer_to_index_map)\n",
    "    customer_df.drop(['customer_id'], axis = 1, inplace = True)\n",
    "\n",
    "    customer_df['user_id'] = pd.Categorical(customer_df['user_id'])\n",
    "    \n",
    "    # convert object variables to category type\n",
    "    categorical_columns = customer_df.select_dtypes(include = 'object').columns\n",
    "    for categorical_column in categorical_columns:\n",
    "        customer_df[categorical_column] = pd.Categorical(customer_df[categorical_column])\n",
    "    # print(customer_df.isnull().sum() / customer_df.shape[0])\n",
    "    \n",
    "    # drop FN, Active\n",
    "    customer_df = customer_df.drop(['FN', 'Active'], axis = 1)\n",
    "    \n",
    "    # fill nan in club_member_status\n",
    "    # print(customer_df.groupby(['club_member_status']).count())\n",
    "    np.random.seed(0)\n",
    "    p = np.array([1260566/1351944, 467/1351944, 90911/1351944])\n",
    "    index = np.random.choice(['ACTIVE', 'LEFTCLUB', 'PRE-CREATE'], p = p.ravel(), size = 6062)\n",
    "    customer_club_null = customer_df[customer_df['club_member_status'].isnull()]\n",
    "    customer_club_not_null = customer_df[~customer_df['club_member_status'].isnull()]\n",
    "    customer_club_null['club_member_status'] = index\n",
    "    customer_df = pd.concat([customer_club_not_null, customer_club_null], axis = 0)\n",
    "    \n",
    "    # fill nan in fashion_news_frequency\n",
    "    # print(customer_df.fashion_news_frequency.value_counts())\n",
    "    customer_fashion_null = customer_df[customer_df['fashion_news_frequency'].isnull()]\n",
    "    p = np.array([877713/1355971, 477416/1355971, 842/1355971])\n",
    "    index = np.random.choice(['NONE', 'Regularly', 'PRE-Monthly'], p = p.ravel(), size = 16009)\n",
    "    customer_fashion_not_null = customer_df[~ customer_df['fashion_news_frequency'].isnull()]\n",
    "    customer_fashion_null['fashion_news_frequency'] = index\n",
    "    customer_df = pd.concat([customer_fashion_not_null, customer_fashion_null], axis = 0)\n",
    "    \n",
    "    # NONE and None can be guessed as the same\n",
    "    customer_fashion_None = customer_df[customer_df['fashion_news_frequency'] == 'None']\n",
    "    customer_fashion_not_None = customer_df[customer_df['fashion_news_frequency'] != 'None']\n",
    "    customer_fashion_None['fashion_news_frequency'] = 'NONE'\n",
    "    customer_df = pd.concat([customer_fashion_None, customer_fashion_not_None], axis = 0)\n",
    "    \n",
    "    # LEFTCLUB and LEFT CLUB can be guessed as the same\n",
    "    customer_club_LEFTCLUB = customer_df[customer_df['club_member_status'] == 'LEFTCLUB']\n",
    "    customer_club_not_LEFTCLUB = customer_df[customer_df['club_member_status'] != 'LEFTCLUB']\n",
    "    customer_club_LEFTCLUB['club_member_status'] = 'LEFT CLUB'\n",
    "    customer_df = pd.concat([customer_club_LEFTCLUB, customer_club_not_LEFTCLUB], axis = 0)\n",
    "    \n",
    "    # fill nan in age columns by using the mean of that grouped by cllub_member_status\n",
    "    customer_age_group = customer_df.groupby('club_member_status')['age'].mean().to_dict()\n",
    "    # print(customer_age_group)\n",
    "    customer_age_null = customer_df[customer_df['age'].isnull()]\n",
    "    customer_age_not_null = customer_df[~ customer_df['age'].isnull()]\n",
    "    customer_age_null_ACTIVE = customer_age_null[customer_age_null['club_member_status'] == 'ACTIVE'] \n",
    "    customer_age_null_ACTIVE['age'] = customer_age_group['ACTIVE']\n",
    "    customer_age_null_LEFTCLUB = customer_age_null[customer_age_null['club_member_status'] == 'LEFT CLUB'] \n",
    "    customer_age_null_LEFTCLUB['age'] = customer_age_group['LEFT CLUB']\n",
    "    customer_age_null_PRECREATE = customer_age_null[customer_age_null['club_member_status'] == 'PRE-CREATE'] \n",
    "    customer_age_null_PRECREATE['age'] = customer_age_group['PRE-CREATE']\n",
    "    customer_df = pd.concat([customer_age_null_ACTIVE, customer_age_null_LEFTCLUB], axis = 0)\n",
    "    customer_df = pd.concat([customer_df, customer_age_null_PRECREATE], axis = 0)\n",
    "    customer_df = pd.concat([customer_df, customer_age_not_null], axis = 0)\n",
    "    \n",
    "   # drop postal_code since it is too much and useless\n",
    "    customer_df = customer_df.drop('postal_code', axis = 1)\n",
    "    # get dummies of club_member_status and fashion_news_frequencydummy\n",
    "    for target_category_col in ['club_member_status', 'fashion_news_frequency']:\n",
    "        customer_df[target_category_col] = label_encoder.fit_transform(customer_df[target_category_col])\n",
    "        customer_df[target_category_col] = pd.Categorical(customer_df[target_category_col])\n",
    "    customer_df_feature = customer_df[['club_member_status', 'fashion_news_frequency', 'age']]\n",
    "    customer_df_id = customer_df['user_id']\n",
    "    customer_df_feature = pd.get_dummies(customer_df_feature, prefix = ['club_member_status', 'fashion_news_frequency'])\n",
    "    customer_df = pd.concat([customer_df_feature, customer_df_id], axis = 1)\n",
    "    return customer_df\n",
    "customer_df = preprocessing_customer_df(customer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d3a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(customer_df, open(f'customer_df.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "388c4aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nthis is fast when after using the model\\n\\n'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_df = pickle.load(open(\"customer_df.pkl\", \"rb\"))\n",
    "'''\n",
    "this is fast when after using the model\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc980310",
   "metadata": {},
   "source": [
    "## combine the dataset and FM part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0bfadb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4c0e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "customer_df = customer_df.sort_values(by = 'user_id')\n",
    "embed = embed.sort_values(by = 'article_id').set_index('article_id').reset_index()\n",
    "dataset = Dataset()\n",
    "dataset.fit(users = customer_df['user_id'], items = embed['article_id'], \n",
    "            item_features = new_col)\n",
    "num_users, num_topics = dataset.interactions_shape()\n",
    "print(f'Number of users: {num_users}, Number of topics: {num_topics}.')\n",
    "(interactions, weights) = dataset.build_interactions(transactions[['user_id', 'article_id']].values)\n",
    "user_features = csr_matrix(customer_df.drop('user_id', axis = 1))\n",
    "item_features = csr_matrix(embed.drop('article_id', axis = 1))\n",
    "data_1 = np.ones(num_users)\n",
    "row_1 = np.ones(num_users)\n",
    "col_1 = np.ones(num_users)\n",
    "customer_sp_csr_1 = sparse.coo_matrix((data, (row, col)), shape = (num_users, num_users)).tocsr()\n",
    "data_2 = np.ones(num_topics)\n",
    "row_2 = np.ones(num_topics)\n",
    "col_2 = np.ones(num_topics)\n",
    "customer_sp_csr_2 = sparse.coo_matrix((data, (row, col)), shape = (num_topics, num_topics)).tocsr()\n",
    "item_features_ = sparse.hstack([customer_sp_csr_2, item_features])\n",
    "modelFM = LightFM(loss='warp', learning_rate = 0.001, random_state = np.random.RandomState(123))\n",
    "modelFM.fit(interactions = interactions, user_features = user_features_,\n",
    "            item_features = item_features_,  epochs = 1)\n",
    "pickle.dump(modelFM, open(DATA_PATH + 'lightFM1.pickle', \"wb\"))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feebafa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sub_customer_id = sub_df.customer_id.map(customer_to_index_map)\n",
    "sub_customer = sub_df.customer_id\n",
    "def get_predictions(customer_id):\n",
    "    pred = modelFM.predict(customer_id, np.arange(embed.shape[0]), user_features = user_features_,\n",
    "            item_features = item_features_)\n",
    "    predict_list = np.argsort(- pred)[:12]\n",
    "    result_list = [lbe_dict['article_id'].inverse_transform([item_id])[0] for item_id in predict_list]\n",
    "    preds = ' '.join(result_list)\n",
    "    return preds\n",
    "customer_id_list_2 = []\n",
    "pred_id_list_2 = []\n",
    "for cus_id_ in tqdm.tqdm(set(sub_customer_id) - set(df_corpus.index)):\n",
    "    customer_id_list_2.append(get_predictions(cus_id_))\n",
    "    pred_id_list_2.append(sub_customer[cus_id_])\n",
    "customer_id_list_2_ = customer_id_list_2.copy()\n",
    "pred_id_list_2_ = pred_id_list_2.copy()\n",
    "pickle.dump(customer_id_list_2, open(f'customer_id_list_2.pkl','wb'))\n",
    "pickle.dump(pred_id_list_2, open(f'pred_id_list_2.pkl','wb'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a83b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "customer_id_list_2 = pickle.load(open(\"customer_id_list_2.pkl\", \"rb\"))\n",
    "pred_id_list_2 = pickle.load(open(\"pred_id_list_2.pkl\", \"rb\"))\n",
    "'''\n",
    "'''\n",
    "this is fast when after using the model\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6231bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sub_pred_df_2 = pd.DataFrame({'prediction': customer_id_list_2, 'customer_id': pred_id_list_2})\n",
    "# prediction and customer_id seem that are converted...., so in sub_pred_df we change that in the true columns\n",
    "sub_pred_df = pd.concat([sub_pred_df_1, sub_pred_df_2], axis = 0)\n",
    "sub_pred_df.to_csv('submission.csv', index = False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebb9e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc1698e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2339e971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2598dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be916f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811f2119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacb2715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cafc14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efce69bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c39fc3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7a6228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b21b3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
